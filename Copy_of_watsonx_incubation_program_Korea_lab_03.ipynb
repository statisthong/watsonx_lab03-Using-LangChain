{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/statisthong/watsonx_lab03-Using-LangChain/blob/main/Copy_of_watsonx_incubation_program_Korea_lab_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "3bb2fd80-43a3-4129-86b4-ac797fd4b610"
      },
      "id": "3bb2fd80-43a3-4129-86b4-ac797fd4b610",
      "cell_type": "markdown",
      "source": [
        "#### lab 3a: LangChain을 사용한 프롬프트 템플릿 만들기 소개"
      ]
    },
    {
      "metadata": {
        "id": "d7a3a7ec"
      },
      "id": "d7a3a7ec",
      "cell_type": "code",
      "source": [
        "!pip install ibm-watson-machine-learning==1.0.311\n",
        "!pip install ipywidgets==8.0.7\n",
        "!pip install jupyter==1.0.0\n",
        "!pip install langchain==0.0.236\n",
        "#!pip install matplotlib==3.7.2\n",
        "!pip install numpy==1.23.5\n",
        "!pip install pandas==1.5.3\n",
        "!pip install plotly==5.15.0\n",
        "#!pip install pypdf==3.12.2\n",
        "!pip install python-dotenv==1.0.0\n",
        "!pip install requests==2.31.0\n",
        "!pip install urllib3==1.26.11\n",
        "!pip install sentence-transformers==2.2.2\n",
        "#!pip install streamlit==1.24.1\n",
        "!pip install safetensors==0.3.1\n",
        "#!pip install faiss-cpu==1.7.4\n",
        "#!pip install pymilvus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "38e1bdbf-5f3d-4ed8-862d-ef704938de90"
      },
      "id": "38e1bdbf-5f3d-4ed8-862d-ef704938de90",
      "cell_type": "code",
      "source": [
        "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
        "from ibm_watson_machine_learning.foundation_models.utils.enums import DecodingMethods\n",
        "from ibm_watson_machine_learning.foundation_models.utils.enums import ModelTypes\n",
        "from langchain.llms.base import LLM\n",
        "from dotenv import load_dotenv\n",
        "from langchain import PromptTemplate, FewShotPromptTemplate\n",
        "import os\n",
        "from ibm_watson_machine_learning.foundation_models import Model\n",
        "from langchain.chains import LLMChain, SimpleSequentialChain\n",
        "from typing import Any, List, Mapping, Optional, Union, Dict\n",
        "\n",
        "API_KEY=\"7JDXm2roHKdgxDtS1bCjmKbbY9jM-dAr8RpEB0HMvWbx\"\n",
        "IBM_CLOUD_URL=\"https://us-south.ml.cloud.ibm.com\"\n",
        "PROJECT_ID=\"a9b59392-efda-46a0-a6b5-0d6af0f60e20\"\n",
        "HUGGINGFACEHUB_API_TOKEN=\"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\"\n",
        "\n",
        "load_dotenv()\n",
        "# api_key = os.getenv(\"API_KEY\", None)\n",
        "api_key = API_KEY\n",
        "# ibm_cloud_url = os.getenv(\"IBM_CLOUD_URL\", 'https://us-south.ml.cloud.ibm.com')\n",
        "ibm_cloud_url = IBM_CLOUD_URL\n",
        "# project_id = os.getenv(\"PROJECT_ID\", None)\n",
        "project_id = PROJECT_ID\n",
        "if api_key is None or ibm_cloud_url is None or project_id is None:\n",
        "    print(\"Ensure you copied the .env file that you created earlier into the same directory as this notebook\")\n",
        "else:\n",
        "    creds = {\n",
        "        \"url\": ibm_cloud_url,\n",
        "        \"apikey\": api_key\n",
        "    }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b6f6dcd7-c7c4-4578-9b85-a8497832ac68"
      },
      "id": "b6f6dcd7-c7c4-4578-9b85-a8497832ac68",
      "cell_type": "code",
      "source": [
        "# Wrap the WatsonX Model in a langchain.llms.base.LLM subclass to allow LangChain to interact with the model\n",
        "\n",
        "class LangChainInterface(LLM):\n",
        "    credentials: Optional[Dict] = None\n",
        "    model: Optional[str] = None\n",
        "    params: Optional[Dict] = None\n",
        "    project_id : Optional[str]=None\n",
        "\n",
        "    @property\n",
        "    def _identifying_params(self) -> Mapping[str, Any]:\n",
        "        \"\"\"Get the identifying parameters.\"\"\"\n",
        "        _params = self.params or {}\n",
        "        return {\n",
        "            **{\"model\": self.model},\n",
        "            **{\"params\": _params},\n",
        "        }\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        \"\"\"Return type of llm.\"\"\"\n",
        "        return \"IBM WATSONX\"\n",
        "\n",
        "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
        "        \"\"\"Call the WatsonX model\"\"\"\n",
        "        params = self.params or {}\n",
        "        model = Model(model_id=self.model, params=params, credentials=self.credentials, project_id=self.project_id)\n",
        "        text = model.generate_text(prompt)\n",
        "        if stop is not None:\n",
        "            text = enforce_stop_tokens(text, stop)\n",
        "        return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f3abe792-7b1b-4bd0-95b2-5d6e24a78c10"
      },
      "id": "f3abe792-7b1b-4bd0-95b2-5d6e24a78c10",
      "cell_type": "code",
      "source": [
        "##predict with the model\n",
        "\n",
        "params = {\n",
        "    GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n",
        "    GenParams.MAX_NEW_TOKENS: 5,\n",
        "    GenParams.MIN_NEW_TOKENS: 1,\n",
        "    GenParams.TEMPERATURE: 0,\n",
        "    GenParams.TOP_K: 50,\n",
        "    GenParams.TOP_P: 1\n",
        "}\n",
        "\n",
        "\n",
        "'''LangChainInterface 클래스에 모델을 실행하기 위한 래퍼 함수를 ​​추가했으므로 우리가 갖고 있는 model_id를 간단히 호출합니다.'''\n",
        "mt_model = \"bigscience/mt0-xxl\"\n",
        "llama2= \"meta-llama/llama-2-70b-chat\"\n",
        "\n",
        "#Lalu kita dapat mencoba mengajukan pertanyaan sederhana dan lihat bagaimana model memberikan respon\n",
        "model_list = [mt_model, llama2]\n",
        "text = \"대한민국의 수도는 어딘지 말해주세요? 정답:\"\n",
        "for i in model_list:\n",
        "    llm_model = LangChainInterface(model=i, credentials=creds, params=params, project_id=project_id)\n",
        "    print(f\"\\nModel {i} 결과:\")\n",
        "    print(llm_model(text))\n",
        "    print({i})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1b3b1520-2206-4c15-9242-31a37b479f28"
      },
      "id": "1b3b1520-2206-4c15-9242-31a37b479f28",
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    GenParams.DECODING_METHOD: DecodingMethods.SAMPLE,\n",
        "    GenParams.MAX_NEW_TOKENS: 100,\n",
        "    GenParams.MIN_NEW_TOKENS: 1,\n",
        "    GenParams.TEMPERATURE: 0.5,\n",
        "    GenParams.TOP_K: 50,\n",
        "    GenParams.TOP_P: 1\n",
        "}\n",
        "\n",
        "# Define the prompt templates\n",
        "prompt = PromptTemplate(\n",
        "  input_variables=[\"country\"],\n",
        "  template= \"{country}의 수도는 어디입니까:\",\n",
        ")\n",
        "llm_model = LangChainInterface(model=mt_model, credentials=creds, params=params, project_id=project_id)\n",
        "# Chaining\n",
        "chain = LLMChain(llm=llm_model, prompt=prompt)\n",
        "\n",
        "# Getting predictions\n",
        "countries = [\"미국\", \"영국\", \"일본\", \"사우디아라비야\"]\n",
        "for country in countries:\n",
        "    response = chain.run(country)\n",
        "    print(prompt.format(country=country) + \" = \" + response)\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3a59d88d-b626-40b5-8eff-ae66f80dcc3c"
      },
      "id": "3a59d88d-b626-40b5-8eff-ae66f80dcc3c",
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    GenParams.DECODING_METHOD: DecodingMethods.SAMPLE,\n",
        "    GenParams.MAX_NEW_TOKENS: 100,\n",
        "    GenParams.MIN_NEW_TOKENS: 1,\n",
        "    GenParams.TEMPERATURE: 0.5,\n",
        "    GenParams.TOP_K: 50,\n",
        "    GenParams.TOP_P: 1\n",
        "}\n",
        "\n",
        "## Create two sequential prompts\n",
        "pt1 = PromptTemplate(input_variables=[\"topic\"],\n",
        "                    template=\"{topic} 주제와 관련된 질문을 작성하세요: 질문:\")\n",
        "pt2 = PromptTemplate(input_variables=[\"question\"],\n",
        "                     template=\"다음 질문에 답하세요: {question}\"\n",
        ")\n",
        "question_model = LangChainInterface(model=mt_model, credentials=creds, params=params, project_id=project_id)\n",
        "answer_model=  LangChainInterface(model=mt_model, credentials=creds, params=params, project_id=project_id)\n",
        "\n",
        "prompt_to_question= LLMChain(llm=question_model, prompt=pt1)\n",
        "question_to_answer = LLMChain(llm=answer_model, prompt=pt2)\n",
        "qa = SimpleSequentialChain(chains=[prompt_to_question, question_to_answer], verbose=True)\n",
        "qa.run(\"삶\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a643015b-459d-4343-ad41-0be3a94702d3"
      },
      "id": "a643015b-459d-4343-ad41-0be3a94702d3",
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "44208b0e-64a0-4939-a814-1830aa340247"
      },
      "id": "44208b0e-64a0-4939-a814-1830aa340247",
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### lab 3b: LangChain을 사용한 프롬프트 템플릿 만들기 소개\n",
        "lab 3에 오신 것을 환영합니다.\n",
        "\n",
        "이전 랩에서는 프롬프트 엔지니어링의 어려움을 탐험했습니다. 어떻게 문구를 조정하고 다른 모델을 선택하며 모델 매개변수를 최적화하는지를 배워보았습니다. 작은 변경이 언어 모델이 생성하는 결과를 크게 향상시킬 수 있습니다.\n",
        "\n",
        "이번 랩에서는 실제 사례에 새로운 지식을 적용하면서 프롬프트 코딩과 관련된 모범 사례에 대해 계속 배우겠습니다. Watson Machine Learning Python SDK를 사용하여 watsonx.ai와 프로그래밍적으로 상호 작용하면서, LangChain Python 라이브러리에서 제공하는 프롬프트 템플릿 기술을 사용하여 언어 모델과의 상호 작용을 최적화하고 그 잠재력을 극대화할 것입니다.\n",
        "\n",
        "LangChain이 제공하는 프롬프트 템플릿의 개념을 사용하면 특정 정보로 쉽게 채워질 수 있는 프롬프트 템플릿을 만들 수 있습니다. 이를 통해 watsonx.ai에 제공할 수 있는 다양한 결과를 생성할 수 있습니다. 아래에서 볼 수 있듯이 퓨-샷 프롬프팅에 특화된 프롬프트 템플릿을 활용할 수도 있습니다.\n",
        "\n",
        "LangChain 프롬프트 패턴을 사용하여 Prompt Builder 프롬프트 재생성\n",
        "시나리오: XYZ 소매 회사를 위한 맞춤형 추천\n",
        "XYZ Retail은 전자제품, 의류, 가정용품 등 다양한 제품을 판매하는 인기있는 온라인 소매점입니다. 그들은 큰 고객 기반을 보유하고 고객 만족도를 높이고 매출을 증대하기 위해 맞춤형 쇼핑 경험을 제공하고자 합니다.\n",
        "\n",
        "이 목표를 달성하기 위해 XYZ는 생성적 AI를 활용하여 각 고객에 대한 팩트 시트를 작성하려고 합니다. 이러한 팩트 시트에는 고객 인구 통계 (이름, 나이, 위치) 및 구매 내역과 같은 관련 정보가 요약될 것입니다. 이러한 팩트 시트는 XYZ 소매의 영업 팀이 더 강력한 고객 관계를 구축하고 고객 만족도를 높이며 반복 구매를 촉진하는 데 도움이 될 것입니다.\n",
        "\n",
        "당신은 Prompt Lab에서 프롬프트 엔지니어링을 수행하기 시작하고 다음과 같은 초기 프롬프트로 기본 모델 출력을 테스트할 수 있습니다.\n",
        "\n",
        "![image.png](attachment:e698a2d9-ef55-4a02-8916-f75c2e4a9271.png)\n",
        "\n",
        "고객 Michael Jones의 경우 모델의 추천이 정확하지 않거나 유용하지 않습니다. 다행히 Prompt Engineering 랩에서 Few Shot Learning이 더 나은 결과를 얻는 데 도움이 될 수 있다는 것을 배웠습니다.\n",
        "\n",
        "Prompt Builder를 사용하여 몇 가지 예를 제공하면 어떻게 될까요? LLM을 유의미한 추천을 생성하도록 안내합니다.\n",
        "\n",
        "![image.png](attachment:085de7fa-ec38-42a5-8ba9-b4820a767f95.png)\n",
        "\n",
        "멋져요, Michael Jones에 대한 제품 추천이 훨씬 나아졌습니다. 그러나 XYZ Retail 모든 고객에 대한 추천을 생성하려면 few shot 프롬프팅을 어떻게 프로덕션화해야 할까요? 각 고객의 정보를 Prompt Builder에 복사하여 붙이는 것은 너무 오래 걸릴 것입니다.\n",
        "\n",
        "프로그래밍 솔루션이 필요합니다. 심지어 많은 예제를 생성한 다음 watsonx.ai에서 모델을 튜닝하는 데 사용할 수도 있을 것입니다. 그러나 이런 내용은 나중의 랩에서 프롬프트 튜닝 데이터 세트를 구축하는 방법에 대해 배우게 될 것입니다.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "d27539a1-41c3-4135-ad4b-c14005220581"
      },
      "id": "d27539a1-41c3-4135-ad4b-c14005220581",
      "cell_type": "markdown",
      "source": [
        "### 1. Load the required libraries"
      ]
    },
    {
      "metadata": {
        "id": "58bde4c5-759b-40a8-86e9-7fab5721d68d"
      },
      "id": "58bde4c5-759b-40a8-86e9-7fab5721d68d",
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "import pandas as pd\n",
        "from langchain import PromptTemplate, FewShotPromptTemplate\n",
        "from ibm_watson_machine_learning.foundation_models import Model\n",
        "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7352cf2e-11e9-41fd-8c40-764b949978c4"
      },
      "id": "7352cf2e-11e9-41fd-8c40-764b949978c4",
      "cell_type": "markdown",
      "source": [
        "### 2. 각 고객에 대한 팩트시트 작성하기 - 프롬프트 패턴 사용\n",
        "2.1 프롬프트 템플릿이란 무엇인가요?\n",
        "LangChain Python 라이브러리의 PromptTemplate 클래스는 구조화된 템플릿에서 프롬프트를 만들기 위한 유연한 방법을 제공합니다. 우리는 PromptTemplate 클래스를 사용하여 XYZ Retail의 few shot 프롬프트를 간단히 만들 것입니다.\n",
        "\n",
        "XYZ Retail은 고객 데이터를 .csv 형식으로 제공했습니다. 각 고객에 대한 프롬프트를 생성하려면 Prompt Builder에서 엔지니어링한 프롬프트를 보다 유용한 프로그래밍 형식으로 변환해야 합니다. PromptTemplate 클래스를 사용하면 고객 데이터를 쉽게 대체하여 하나 이상의 프롬프트를 생성할 수 있습니다.\n",
        "\n",
        "PromptTemplate 클래스는 대체할 변수가 중괄호 내에 위치하는 스키마를 정의합니다. Python 용어로는 그저 하드코딩된 \"f-strings\"를 사용하는 것입니다. 이러한 중괄호는 실제 데이터를 템플릿에 대체할 자리 표시자로 작용합니다.\n",
        "\n",
        "이것이 실제로 어떻게 동작하는지 살펴보겠습니다.\n",
        "\n",
        "#### 2.2 템플릿에서 간단한 프롬프트 생성\n",
        "프롬프트 템플릿은 PromptTemplate 클래스를 사용하여 문자열이나 .txt 파일에서 생성할 수 있습니다. LangChain 문서에는 추가적인 PromptTemplate 예제가 제공됩니다.\n",
        "\n",
        "#### 2.2.1 문자열에서 프롬프트 템플릿 만들기"
      ]
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7a35dad6-9244-4378-b79e-990acb276c9e",
        "outputId": "135acfe0-eaf0-4006-9430-b949b0f6c4a3"
      },
      "id": "7a35dad6-9244-4378-b79e-990acb276c9e",
      "cell_type": "code",
      "source": [
        "\n",
        "# template is a string with variable names in curly brackets\n",
        "pattern = \"input: {name} {family_name} 은 {age} 살 입니다. 사는곳은 {location}. 그는 {purchase_history}을 샀습니다.\"\n",
        "\n",
        "# generate template\n",
        "prompt_template = PromptTemplate.from_template(pattern)\n",
        "prompt_template.template"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'input: {name} {family_name} 은 {age} 살 입니다. 사는곳은 {location}. 그는 {purchase_history}을 샀습니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "844bb28b-6318-4184-b1da-30ccb8425bed"
      },
      "id": "844bb28b-6318-4184-b1da-30ccb8425bed",
      "cell_type": "code",
      "source": [
        "# now let's provide some values and generate our prompt\n",
        "# notice how the variables coincide with those we specified in curly brackets\n",
        "prompt = prompt_template.format(name=\"유진\",\n",
        "                                family_name=\"김\",\n",
        "                                age=34,\n",
        "                                location=\"용인시 수지구\",\n",
        "                                purchase_history = \"식료품, 가정용품, 생필품\")\n",
        "\n",
        "prompt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "091fd8d9-58aa-4cda-aa13-7390687635cf"
      },
      "id": "091fd8d9-58aa-4cda-aa13-7390687635cf",
      "cell_type": "markdown",
      "source": [
        "#### 2.2.2 텍스트 파일에서 프롬프트 템플릿\n",
        "\n",
        "프롬프트 패턴은 텍스트 파일로 저장할 수도 있습니다.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heoBDTWtNmJT",
        "outputId": "244740ff-f45f-4e63-dc48-d09f4e4d5592"
      },
      "id": "heoBDTWtNmJT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "f646a3dc-2888-488b-8cfe-796e949b0919"
      },
      "id": "f646a3dc-2888-488b-8cfe-796e949b0919",
      "cell_type": "code",
      "source": [
        "\n",
        "# We create a template from a file:\n",
        "#_path_to_file = \"./template/customer_factsheet_lang.txt\"\n",
        "\n",
        "_path_to_file = '/content/drive/MyDrive/customer_factsheet_lang.txt'\n",
        "\n",
        "# this time we provide the variable names in a list\n",
        "example_prompt = PromptTemplate.from_file(_path_to_file,\n",
        "                                input_variables=[\"name\", \"family_name\", \"age\",\"city\",\n",
        "                                                 \"purchase_history\", \"recommendation_1\", \"recommendation_2\"])\n",
        "\n",
        "print(example_prompt.template)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "64ebdaa7-1f63-4d2a-b478-f3ccc4620031"
      },
      "id": "64ebdaa7-1f63-4d2a-b478-f3ccc4620031",
      "cell_type": "markdown",
      "source": [
        "#### 2.1 처럼 이 템플릿을 입력 변수의 값이 들어 있는 딕셔너리에서 채울 수 있습니다."
      ]
    },
    {
      "metadata": {
        "id": "0eebef7d-f4bf-4d92-899e-c3c40e3a2cac"
      },
      "id": "0eebef7d-f4bf-4d92-899e-c3c40e3a2cac",
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "    {\n",
        "        \"name\": \"상식\",\n",
        "        \"family_name\": \"박\",\n",
        "        \"age\": 43,\n",
        "        \"city\": \"샌프란시스코\",\n",
        "        \"purchase_history\": \"식료품, 생활용품 및 여행 용품\",\n",
        "        \"recommendation_1\": \"유기농 과일 바구니\",\n",
        "        \"recommendation_2\": \"경량 캐리어\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"민희\",\n",
        "        \"family_name\": \"김\",\n",
        "        \"age\": 57,\n",
        "        \"city\": \"시카고\",\n",
        "        \"purchase_history\": \"도서, 전자제품, 가정용품\",\n",
        "        \"recommendation_1\": \"Kindle Paperwhite - 이 전자 책 리더는 수천 권의 책을 저장할 수 있는 가벼우면서 휴대 가능한 장치를 원하는 도서 애호가를 위한 것입니다. 눈부림이 없는 디스플레이와 긴 배터리 수명이 특징이며 전원이 바닥나는 걱정 없이 몇 시간 동안 읽을 수 있습니다.\",\n",
        "        \"recommendation_2\": \"Google Home Mini - 이 스마트 스피커는 음성으로 집의 스마트 기기를 제어하기에 완벽합니다. 음악 재생, 알람 설정, 뉴스 받아보기 등 다양한 용도로 사용할 수 있습니다. 또한 친구와 가족과 연결되는 좋은 방법입니다.\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"은정\",\n",
        "        \"family_name\": \"박\",\n",
        "        \"age\": 21,\n",
        "        \"city\": \"뉴욕 시티\",\n",
        "        \"purchase_history\": \"의류, 신발, 화장품\",\n",
        "        \"recommendation_1\": \"Aritzia Wilfred Free Sweater - 이 부드럽고 아늑한 스웨터는 캐주얼한 외출에 완벽합니다. 다양한 색상으로 제공되어 스타일에 맞는 완벽한 색상을 찾을 수 있습니다.\",\n",
        "        \"recommendation_2\": \"Steve Madden Pointed Toe Pumps - 이 세련된 펌프는 도시에서의 야외 약속에 완벽합니다. 편안하고 다양한 의상에 매치할 수 있어 다양한 의상에 착용할 수 있습니다.\"\n",
        "    }\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d48a11f-9e1c-4e34-8ca5-4457950d337c",
        "outputId": "a94ba229-23b7-4dec-f7cc-e77115f0627d"
      },
      "id": "0d48a11f-9e1c-4e34-8ca5-4457950d337c",
      "cell_type": "code",
      "source": [
        "for example in examples:\n",
        "    print(example_prompt.format(**example))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: 상식 박 은 43살 입니다. 그리고 샌프란시스코에 거주합니다. 그는 식료품, 생활용품 및 여행 용품을(를) 샀습니다.\n",
            "output: Recommendations: Item 1: 유기농 과일 바구니 Item 2: 경량 캐리어\n",
            "input: 민희 김 은 57살 입니다. 그리고 시카고에 거주합니다. 그는 도서, 전자제품, 가정용품을(를) 샀습니다.\n",
            "output: Recommendations: Item 1: Kindle Paperwhite - 이 전자 책 리더는 수천 권의 책을 저장할 수 있는 가벼우면서 휴대 가능한 장치를 원하는 도서 애호가를 위한 것입니다. 눈부림이 없는 디스플레이와 긴 배터리 수명이 특징이며 전원이 바닥나는 걱정 없이 몇 시간 동안 읽을 수 있습니다. Item 2: Google Home Mini - 이 스마트 스피커는 음성으로 집의 스마트 기기를 제어하기에 완벽합니다. 음악 재생, 알람 설정, 뉴스 받아보기 등 다양한 용도로 사용할 수 있습니다. 또한 친구와 가족과 연결되는 좋은 방법입니다.\n",
            "input: 은정 박 은 21살 입니다. 그리고 뉴욕 시티에 거주합니다. 그는 의류, 신발, 화장품을(를) 샀습니다.\n",
            "output: Recommendations: Item 1: Aritzia Wilfred Free Sweater - 이 부드럽고 아늑한 스웨터는 캐주얼한 외출에 완벽합니다. 다양한 색상으로 제공되어 스타일에 맞는 완벽한 색상을 찾을 수 있습니다. Item 2: Steve Madden Pointed Toe Pumps - 이 세련된 펌프는 도시에서의 야외 약속에 완벽합니다. 편안하고 다양한 의상에 매치할 수 있어 다양한 의상에 착용할 수 있습니다.\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "b40bb8dd-c015-43f3-9d26-38b7aa2d473e"
      },
      "id": "b40bb8dd-c015-43f3-9d26-38b7aa2d473e",
      "cell_type": "markdown",
      "source": [
        "### 3. 고객 요약서를 기반으로 프롬프트 예시 생성\n",
        "PromptTemplate의 가치는 엔지니어링된 프롬프트의 대량 평가용 예시 또는 튜닝 데이터셋을 생성할 때 많은 프롬프트를 생성할 때 나타납니다.\n",
        "\n",
        "#### 3.1 FewShot 프롬프트 생성\n",
        "우리는 FewShotPromptTemplate 객체를 생성하여 시작할 것입니다. 이 클래스는 PromptTemplate의 몇 번의 반복으로 구성된 프롬프트를 만들 수 있게 해줍니다. 자세한 내용은 FewShotPromptTemplate 클래스 문서에서 확인할 수 있습니다.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "d74b48f5-8e37-4e6a-9d2a-092ed5d01f71"
      },
      "id": "d74b48f5-8e37-4e6a-9d2a-092ed5d01f71",
      "cell_type": "code",
      "source": [
        "# Next step create a few shot prompt template\n",
        "\n",
        "few_shot_examples = examples[:2]\n",
        "few_shot_input = examples[2].copy()\n",
        "del few_shot_input['recommendation_1']\n",
        "del few_shot_input['recommendation_2']\n",
        "\n",
        "def make_few_shot_prompt(few_shot_examples, few_shot_input):\n",
        "    \"\"\"\n",
        "    Generate a few-shot prompt using the FewShotPromptTemplate class.\n",
        "\n",
        "    Parameters:\n",
        "    - few_shot_examples: List of examples to be shown as few-shot examples.\n",
        "    - few_shot_input: Input for which the prompt will be generated.\n",
        "\n",
        "    Returns:\n",
        "    - A string representing the formatted few-shot prompt.\n",
        "    \"\"\"\n",
        "    prompt = FewShotPromptTemplate(\n",
        "        examples=few_shot_examples,\n",
        "        example_prompt=example_prompt,\n",
        "        suffix='input: \"{name} {family_name} 은 {age}살 입니다. 그리고 {city}에 거주합니다. 그는 {purchase_history}을(를) 샀습니다.\"\\noutput: ',\n",
        "        input_variables=[\"name\", \"family_name\", \"age\", \"city\", \"purchase_history\"]\n",
        "    )\n",
        "    # Return the formatted prompt using the provided input data\n",
        "    return prompt.format(**few_shot_input)\n",
        "\n",
        "\n",
        "few_shot_prompt = make_few_shot_prompt(few_shot_examples, few_shot_input)\n",
        "print(few_shot_prompt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "21e69e29-8547-445e-89da-871b57505cad"
      },
      "id": "21e69e29-8547-445e-89da-871b57505cad",
      "cell_type": "markdown",
      "source": [
        "#### 3.2 프롬프트 대량 생성\n",
        "FewShotPromptTemplate 클래스를 사용하여 이제 노트북에서 직접 추출한 값으로 반복적으로 채워진 few shot 프롬프트 목록을 생성하는 함수를 만들 수 있습니다.\n",
        "\n",
        "한 few shot 프롬프트에 몇 개의 단일 프롬프트를 포함할지 선택할 수 있습니다. 함수의 출력은 few shot 프롬프트의 목록입니다.\n"
      ]
    },
    {
      "metadata": {
        "id": "0ca01e48-c503-47ba-b31c-828690a58cc6"
      },
      "id": "0ca01e48-c503-47ba-b31c-828690a58cc6",
      "cell_type": "code",
      "source": [
        "# Specify the path to the CSV file containing the data\n",
        "csv_file_path = \"/content/drive/MyDrive/customer_factsheet.csv\"\n",
        "\n",
        "def sub_all_from_csv(csv_file_path, n_prompt_examples=2):\n",
        "    \"\"\"\n",
        "    Generates a list of few-shot prompts using the FewShotPromptTemplate class.\n",
        "    The prompts are populated iteratively from values extracted from a CSV file.\n",
        "\n",
        "    Parameters:\n",
        "    - csv_file_path: The path to the CSV file.\n",
        "    - n_prompt_examples: The number of examples included in one few-shot prompt.\n",
        "\n",
        "    Returns:\n",
        "    - list_of_prompts: A list of few-shot prompts.\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_csv(csv_file_path)\n",
        "    examples = [example for _, example in df.transpose().to_dict().items()]\n",
        "    i=0\n",
        "    list_of_prompts = []\n",
        "\n",
        "    while i < len(df):\n",
        "        few_shot_examples = examples[i:i+n_prompt_examples]\n",
        "        few_shot_input = examples[i+n_prompt_examples].copy()\n",
        "        del few_shot_input['recommendation_1']\n",
        "        del few_shot_input['recommendation_2']\n",
        "\n",
        "        list_of_prompts.append(make_few_shot_prompt(few_shot_examples, few_shot_input))\n",
        "\n",
        "        i = i+n_prompt_examples +1\n",
        "\n",
        "    # Return the list of few-shot prompts\n",
        "    return list_of_prompts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50093338-eab8-4813-b5be-b9f58f41b09c",
        "outputId": "fadacdc0-5408-43bb-a556-923605efba4b"
      },
      "id": "50093338-eab8-4813-b5be-b9f58f41b09c",
      "cell_type": "code",
      "source": [
        "list_of_prompts = sub_all_from_csv(csv_file_path)\n",
        "print(list_of_prompts[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: 유진 김 은 30살 입니다. 그리고 용인에 거주합니다. 그는 도서, 전자제품, 가정용품을(를) 샀습니다.\n",
            "output: Recommendations: Item 1: Kindle Paperwhite - 이 전자 책 리더는 수천 권의 책을 저장할 수 있는 가벼우면서 휴대 가능한 장치를 원하는 도서 애호가를 위한 것입니다. 눈부림이 없는 디스플레이와 긴 배터리 수명이 특징이며 전원이 바닥나는 걱정 없이 몇 시간 동안 읽을 수 있습니다. Item 2: Google Home Mini - 이 스마트 스피커는 음성으로 집의 스마트 기기를 제어하기에 완벽합니다. 음악 재생, 알람 설정, 뉴스 받아보기 등 다양한 용도로 사용할 수 있습니다. 또한 친구와 가족과 연결되는 좋은 방법입니다.\n",
            "\n",
            "input: 용국 \b방 은 25살 입니다. 그리고 \b진주에 거주합니다. 그는 의류, 신발, 화장품을(를) 샀습니다.\n",
            "output: Recommendations: Item 1: Aritzia Wilfred Free Sweater - 이 부드럽고 아늑한 스웨터는 캐주얼한 외출에 완벽합니다. 다양한 색상으로 제공되어 스타일에 맞는 완벽한 색상을 찾을 수 있습니다. Item 2: Steve Madden Pointed Toe Pumps - 이 세련된 펌프는 도시에서의 야외 약속에 완벽합니다. 편안하고 다양한 의상에 매치할 수 있어 다양한 의상에 착용할 수 있습니다.\n",
            "\n",
            "input: \"찬영 강 은 40살 입니다. 그리고 전주에 거주합니다. 그는 장난감, 게임, 스포츠용품을(를) 샀습니다.\"\n",
            "output: \n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "07e98455-05e0-489a-b99a-0b381fc60dee",
        "outputId": "95af1a25-b51d-408b-cce4-01c4d0e2084b"
      },
      "id": "07e98455-05e0-489a-b99a-0b381fc60dee",
      "cell_type": "code",
      "source": [
        "list_of_prompts[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'input: 환 곽 은 35살 입니다. 그리고 강릉에 거주합니다. 그는 전자제품, 가정 개선, 스포츠용품을(를) 샀습니다.\\noutput: Recommendations: Item 1: 무선 헤드폰 Item 2: 전동 공구\\n\\ninput: \\x08현태 김 은 45살 입니다. 그리고 목포에 거주합니다. 그는 도서, 음악, 영화을(를) 샀습니다.\\noutput: Recommendations: Item 1: 베스트셀러 소설 Item 2: 비닐 레코드\\n\\ninput: \"기연 전 은 55살 입니다. 그리고 안산에 거주합니다. 그는 가구, 가전제품, 가정용품을(를) 샀습니다.\"\\noutput: '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "8b0d16bb-8c97-4c82-95d0-d72bcabe3527"
      },
      "id": "8b0d16bb-8c97-4c82-95d0-d72bcabe3527",
      "cell_type": "markdown",
      "source": [
        "#### 3.2 추가 예시\n",
        "PromptTemplate을 사용하여 추가 예시를 탐색할 수 있습니다.\n",
        "\n",
        "### 4. 프롬프트 평가 및 대량 생성된 프롬프트로부터의 퓨 샷 러닝\n",
        "이전 예제에서 \"2 샷 러닝\" 프롬프트를 생성했습니다. 즉, 세 개의 입력이 있지만 두 개의 완전한 출력만 있었습니다. 이 방법으로 더 큰 데이터셋을 사용하면 프롬프트를 대량으로 테스트할 수 있습니다.\n",
        "\n",
        "예를 들어 데이터 샘플 중 두 개는 훈련에 사용되고 3번째의 \"출력\"은 모델 출력과 비교하여 프롬프트가 예상대로 작동하는지 확인할 수 있습니다. 이제 이러한 퓨 샷 프롬프트를 실행하여 엔지니어링된 프롬프트가 다양한 예제에서 얼마나 잘 작동하는지 확인할 수 있습니다.\n",
        "\n",
        "#### 4.1 Watsonx.ai 액세스 자격 증명 가져오기 및 모델 로드\n",
        "이전에 생성한 .env 파일을 이 노트북과 동일한 디렉토리로 복사했는지 확인하세요."
      ]
    },
    {
      "metadata": {
        "id": "f9569f5f-64f8-4dcb-9471-e89f8cdef7ec"
      },
      "id": "f9569f5f-64f8-4dcb-9471-e89f8cdef7ec",
      "cell_type": "code",
      "source": [
        "API_KEY=\"7JDXm2roHKdgxDtS1bCjmKbbY9jM-dAr8RpEB0HMvWbx\"\n",
        "IBM_CLOUD_URL=\"https://us-south.ml.cloud.ibm.com\"\n",
        "PROJECT_ID=\"a9b59392-efda-46a0-a6b5-0d6af0f60e20\"\n",
        "HUGGINGFACEHUB_API_TOKEN=\"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\"\n",
        "\n",
        "#load_dotenv()\n",
        "#api_key = os.getenv(\"API_KEY\", None)\n",
        "api_key = API_KEY\n",
        "#ibm_cloud_url = os.getenv(\"IBM_CLOUD_URL\", 'https://us-south.ml.cloud.ibm.com')\n",
        "ibm_cloud_url = IBM_CLOUD_URL\n",
        "#project_id = os.getenv(\"PROJECT_ID\", None)\n",
        "project_id = PROJECT_ID\n",
        "if api_key is None or ibm_cloud_url is None or project_id is None:\n",
        "    print(\"Ensure you copied the .env file that you created earlier into the same directory as this notebook\")\n",
        "else:\n",
        "    creds = {\n",
        "        \"url\": ibm_cloud_url,\n",
        "        \"apikey\": api_key\n",
        "    }\n",
        "\n",
        "\n",
        "model_params = {\n",
        "    GenParams.DECODING_METHOD: \"greedy\",\n",
        "    GenParams.MIN_NEW_TOKENS: 50,\n",
        "    GenParams.MAX_NEW_TOKENS: 200,\n",
        "    GenParams.STOP_SEQUENCES: [\"\\n\\n\"]\n",
        "}\n",
        "\n",
        "# Instantiate a model proxy object to send your requests\n",
        "model = Model(\n",
        "    model_id='meta-llama/llama-2-70b-chat',\n",
        "    params=model_params,\n",
        "    credentials=creds,\n",
        "    project_id=project_id)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "13894c90-dd6e-4c39-b8eb-25ee32494b93"
      },
      "id": "13894c90-dd6e-4c39-b8eb-25ee32494b93",
      "cell_type": "code",
      "source": [
        "responses = [model.generate_text(prompt) for prompt in list_of_prompts]\n",
        "for i, response in enumerate(responses):\n",
        "    lines = str(list_of_prompts[i]).strip().split(\"\\n\")\n",
        "    user_description = str(lines[8])\n",
        "    print(f\"\\n{user_description}\")\n",
        "    print(f\"\\noutput: {response}\")\n",
        "    print(\"---------------------\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4b6ab360-a9b7-4c11-adf0-ad2b499f1ad3"
      },
      "id": "4b6ab360-a9b7-4c11-adf0-ad2b499f1ad3",
      "cell_type": "markdown",
      "source": [
        "### 퓨 샷 프롬프트 분석\n",
        "이러한 결과는 나쁘지 않습니다. 장난감과 게임을 많이 구매한 고객에 대한 전자제품 추천, 마찬가지로 다른 두 명의 고객에 대해서는 화장품 및 가구가 구매 이력을 정확하게 반영하고 있습니다.\n",
        "\n",
        "모델은 제품에 대한 자세한 설명 대신 더 많은 추천 항목을 추가하는 경우도 있습니다. 이러한 추가 항목은 추가 항목에 대한 훈련 데이터가 없으므로 정확하지 않습니다.\n",
        "\n",
        "앞부분에 지시사항을 추가하는 것도 도움이 될 것으로 보입니다. 이것은 여러분이 시도해볼 연습이 될 것입니다.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ee79bab5-201e-471a-943f-b9870fca5b5f"
      },
      "id": "ee79bab5-201e-471a-943f-b9870fca5b5f",
      "cell_type": "markdown",
      "source": [
        "#### 4.3 Additional Technique on Few Shot Prompt Analysis"
      ]
    },
    {
      "metadata": {
        "id": "e71bebc6-6804-426c-8fd0-d5e501eabc17"
      },
      "id": "e71bebc6-6804-426c-8fd0-d5e501eabc17",
      "cell_type": "code",
      "source": [
        "def new_shot(values):\n",
        "    '''\"이전에 사용한 프롬프트 대부분은 데이터/customer_factsheet.csv 디렉토리에 생성된 팩트 시트에서 데이터를 가져오지만,\n",
        "    이 함수는 분석이나 입력으로 사용할 새로운 데이터를 생성하는 데 도움이 될 것입니다.\"'''\n",
        "    keys = ['name', 'family_name', 'age', 'city', 'purchase_history', 'recommendation_1', 'recommendation_2']\n",
        "    prompt_shot = dict(zip(keys, values))\n",
        "    return prompt_shot\n",
        "\n",
        "new_values = [ '소연', '권', 50, '광주', '게임, 컴퓨터, 텀블러']\n",
        "new_shot_input = new_shot(new_values)\n",
        "# Function\n",
        "csv_file_path = \"/content/drive/MyDrive/customer_factsheet.csv\"\n",
        "df = pd.read_csv(csv_file_path)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b4b8a331-ff67-4dbb-b894-b24c1295184c"
      },
      "id": "b4b8a331-ff67-4dbb-b894-b24c1295184c",
      "cell_type": "code",
      "source": [
        "new_shot_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cc59366f-d125-4639-bc6f-efe9525965dc"
      },
      "id": "cc59366f-d125-4639-bc6f-efe9525965dc",
      "cell_type": "code",
      "source": [
        "def few_shot(name_to_test, number_of_examples, no_extra_sample=True, new_shot=None):\n",
        "\n",
        "    '''\n",
        "    이 함수는 Generative AI 모델에서 사용할 수 있는 형식으로 데이터 시트를 생성하는 데 유용합니다.\n",
        "    name_to_test = 테스트하려는 사용자의 이름을 채우는 변수로, 이미 팩트 시트에 포함되어 있어야 합니다.\n",
        "    number_of_example = 사용할 퓨 샷 테스트의 수\n",
        "    no_extra_sample = True -> 시트에 이미 있는 데이터를 사용\n",
        "    False -> \"few_shot\" 함수에서 호출할 새로운 데이터 사용\n",
        "    new_shot = False가 아닐 때 호출할 새로운 데이터 변수\n",
        "    '''\n",
        "\n",
        "    # Filter the DataFrame to exclude specified names\n",
        "    df_filtered = df[~df['name'].isin(name_to_test)]\n",
        "    few_shot_train = [example for _, example in df_filtered.transpose().to_dict().items()]\n",
        "    print(few_shot_train)\n",
        "    #print(df_filtered)\n",
        "    print(\"==\")\n",
        "    print(df[df['name'].isin(name_to_test)].iloc[0].to_dict())\n",
        "    print(\"==\")\n",
        "    if no_extra_sample==True:\n",
        "        few_shot_test = df[df['name'].isin(name_to_test)].iloc[0].to_dict()\n",
        "        few_shot_test.pop('recommendation_1', None)\n",
        "        few_shot_test.pop('recommendation_2', None)\n",
        "    else:\n",
        "        few_shot_input = new_shot\n",
        "\n",
        "    return make_few_shot_prompt(few_shot_train[:number_of_examples - 1], few_shot_test)\n",
        "\n",
        "few_shot_model = few_shot(name_to_test=['유진'], number_of_examples=4, no_extra_sample=True, new_shot = new_shot_input)\n",
        "print(few_shot_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fb26aba7-21d9-4544-8f48-2fabc111b509"
      },
      "id": "fb26aba7-21d9-4544-8f48-2fabc111b509",
      "cell_type": "code",
      "source": [
        "# Generative AI Model\n",
        "'''\"좋은 결과를 얻기 위해 모델 파라미터를 조정해보세요.\"'''\n",
        "model_parameters = {\n",
        "    GenParams.DECODING_METHOD: \"greedy\",\n",
        "    GenParams.MIN_NEW_TOKENS: 1,\n",
        "    GenParams.MAX_NEW_TOKENS: 500,\n",
        "    GenParams.STOP_SEQUENCES: [\"\\n\\n\"]\n",
        "}\n",
        "\n",
        "llama2 = \"meta-llama/llama-2-70b-chat\"\n",
        "\n",
        "model = Model(model_id=llama2,params=model_parameters,credentials=creds,project_id=project_id)\n",
        "\n",
        "def prompt_ID(shot_list):\n",
        "\n",
        "    '''\n",
        "    이 함수는 기존 팩트 시트와 일치하는 제품 추천을 생성하는 데 사용되는 Generative AI 함수입니다.\n",
        "    이 함수의 주요 차이점은 다음과 같습니다:\n",
        "\n",
        "    1. 사용 가능한 퓨 샷 또는 샘플의 수\n",
        "    2. 지시사항, 사용할 Generative AI 모델에 대한 명확성 또는 설명을 제공합니다.\n",
        "    아래에서는 LLAMA2 모델을 위한 프롬프트 템플릿을 사용합니다.\n",
        "    '''\n",
        "    segments = shot_list.split(\"\\n\\ninput:\")\n",
        "    sample_shot_list = \"\\n\\ninput:\".join(segments[:-1])\n",
        "    test_shot = \"input:\" + segments[-1]\n",
        "    prompt_en_id = \"\"\n",
        "    prompt_en_id +=  \"<s>[INST] <<SYS>>\"\\\n",
        "                    f\"{sample_shot_list}\\n\"\\\n",
        "                    \"<</SYS>>\\n\"\\\n",
        "                    \"최대 2가지 품목을 추천하세요!\\n\"\\\n",
        "                    \"당신은 사용자에게 특정 제품 및 브랜드에 관한 권장 사항을 제공하는 AI 모델입니다.\\n\"\\\n",
        "                    \"우리의 소비자들은 이름, 성, 도시 및 거래 내역과 같은 몇 가지 특징을 가지고 있습니다.\\n\"\\\n",
        "                    \"권장 사항은 그들의 거래 내역과 관련이 있고 거래 패턴을 따르도록 하십시오. 아래의 예시처럼 표시된 표시에서\\n\"\\\n",
        "                    \"기억하세요: 가능한 도움이 될 수 있도록 항상 답하되, 안전을 유지하세요. \\n\"\\\n",
        "                    \"당신의 답변은 해로운, 비윤리적, 인종 차별적, 성차별적, 유독성, 위험한 또는 불법적인 내용을 포함해서는 안 됩니다.\\n\"\\\n",
        "                    \"당신의 응답은 사회적으로 편향되지 않고 긍정적인 성격을 가지도록 해주세요.\\n\"\\\n",
        "                    \"위는 예시입니다.:\\n\"\\\n",
        "                    \"[/INST]\"\\\n",
        "                    f\"{test_shot}\"\n",
        "    return prompt_en_id\n",
        "\n",
        "# Call prompt_definitions to get the full prompt\n",
        "prompts = prompt_ID(few_shot_model)\n",
        "responses = model.generate_text(prompts)\n",
        "print(prompts,responses)\n",
        "# print(prompts,responses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d895f4ba-10c3-44ec-96e8-38600164e30a"
      },
      "id": "d895f4ba-10c3-44ec-96e8-38600164e30a",
      "cell_type": "code",
      "source": [
        "#recommendation_1': 'Kindle Paperwhite - 이 전자 책 리더는 수천 권의 책을 저장할 수 있는 가벼우면서 휴대 가능한 장치를 원하는 도서 애호가를 위한 것입니다.\n",
        "#눈부림이 없는 디스플레이와 긴 배터리 수명이 특징이며 전원이 바닥나는 걱정 없이 몇 시간 동안 읽을 수 있습니다.',\n",
        "\n",
        "#'recommendation_2': 'Google Home Mini - 이 스마트 스피커는 음성으로 집의 스마트 기기를 제어하기에 완벽합니다.\n",
        "#음악 재생, 알람 설정, 뉴스 받아보기 등 다양한 용도로 사용할 수 있습니다. 또한 친구와 가족과 연결되는 좋은 방법입니다.'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f37a2486-15bf-4231-a7ae-b8ede579f8c4"
      },
      "id": "f37a2486-15bf-4231-a7ae-b8ede579f8c4",
      "cell_type": "markdown",
      "source": [
        "### 축하합니다\n",
        "PromptTemplate을 사용한 퓨 샷 프롬프트의 대량 생성의 흥미로운 세계를 탐험하고 랩을 완료한 것을 축하합니다!\n",
        "개인 맞춤형 제품 추천을 생성하는 실제 사용 사례를 통해 고객 프로필에 프롬프트를 맞춤 설정하는 힘을 목격했습니다. 고객별 세부 정보를 통합하고 프로그래밍적으로 대량의 예제를 생성함으로써 모델을 튜닝할 수 있으며, 이는 더 정확하고 맞춤형된 결과를 얻게 됩니다.\n",
        "\n",
        "이러한 예제를 기반으로 계속해서 프롬프트를 반복하고 개선함으로써 언어 모델의 전체 잠재력을 발휘하고 다양한 도메인에서의 성능을 향상시킬 수 있습니다. 계속해서 실험을 진행하고 프롬프트 엔지니어링 기술을 활용하여 언어 모델과의 상호 작용을 최적화하고 프로젝트에서 효과적인 결과를 얻어보세요."
      ]
    },
    {
      "metadata": {
        "id": "43101e0d-58fc-4308-ac23-dbf9f9890a70"
      },
      "id": "43101e0d-58fc-4308-ac23-dbf9f9890a70",
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.10",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}